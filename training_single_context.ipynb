{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "edc7e8da127e731d54753afe8930f1420dc6ae9a13010eedc53dff7bbda352d4"
   }
  },
  "interpreter": {
   "hash": "febc8ed225c173224913a33e4bcc13b4e98623c14b3011f9df708a037d5d8a22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Single-Context Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "use_case = 'community-prediction-youtube-n'\r\n",
    "layer_name = 'LikesLayer' \r\n",
    "\r\n",
    "approach = 'single_context'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import pandas as pd\r\n",
    "from pandas import DataFrame\r\n",
    "\r\n",
    "df: DataFrame = pd.read_csv(f'data/{use_case}/ml_input/single_context/{layer_name}.csv', index_col=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# df = df.sample(frac=10000/565824)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "len(df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import numpy as np\r\n",
    "import collections\r\n",
    "\r\n",
    "def split_data(dataframe, test_dataset_frac=.2, shuffle=False) -> '(training_data, test_data)':\r\n",
    "    if shuffle:\r\n",
    "        dataframe = dataframe.sample(frac=1).reset_index(drop=True)\r\n",
    "\r\n",
    "    training_size = int(len(dataframe) * (1-test_dataset_frac))\r\n",
    "\r\n",
    "    train = dataframe[:training_size]\r\n",
    "    test = dataframe[training_size:]\r\n",
    "\r\n",
    "    y_train = train[train.columns[-1]]\r\n",
    "    y_test = test[test.columns[-1]]\r\n",
    "  \r\n",
    "    print(f\"\\nWorking with: {len(train)} training points + {len(test)} test points ({len(test)/(len(test)+len(train))} test ratio).\")\r\n",
    "    print(f\"Label Occurrences: Total = {collections.Counter(y_train.tolist() + y_test.tolist())}, \\n\" \\\r\n",
    "          f\"\\tTraining = {collections.Counter(y_train)}, \\n\" \\\r\n",
    "          f\"\\tTest = {collections.Counter(y_test)}\")\r\n",
    "    # try:\r\n",
    "    #     print(f\"Label Majority Class: Training = {stat.mode(Y_train)}, Test = {stat.mode(Y_test)}\\n\")\r\n",
    "    # except stat.StatisticsError:\r\n",
    "    #     print(f\"Label Majority Class: no unique mode; found 2 equally common values\")\r\n",
    "\r\n",
    "    return train, test\r\n",
    "\r\n",
    "training, testing = split_data(df, shuffle=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Working with: 452659 training points + 113165 test points (0.2000003534668024 test ratio).\n",
      "Label Occurrences: Total = Counter({-1.0: 313795, 4.0: 93192, 3.0: 92757, 0.0: 24818, 1.0: 20679, 2.0: 20583}), \n",
      "\tTraining = Counter({-1.0: 251137, 4.0: 74536, 3.0: 74105, 0.0: 19812, 1.0: 16650, 2.0: 16419}), \n",
      "\tTest = Counter({-1.0: 62658, 4.0: 18656, 3.0: 18652, 0.0: 5006, 2.0: 4164, 1.0: 4029})\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def remove_empty_community_class(df):\r\n",
    "    '''Removes evolution_label -1 from dataset indicating the community stays empty.'''\r\n",
    "    # res = df.loc[df['evolution_label'] != -1.0]\r\n",
    "    # res = res.reset_index(drop=True)\r\n",
    "    # return res\r\n",
    "    df['evolution_label'] = df['evolution_label'].replace(-1.0, 0)\r\n",
    "    return df\r\n",
    "\r\n",
    "training = remove_empty_community_class(training)\r\n",
    "testing = remove_empty_community_class(testing)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "g:\\Arbeit\\community-prediction\\venv\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "training"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        cluster_size  cluster_variance  cluster_density  cluster_import1  \\\n",
       "498290           0.0               0.0              0.0         0.000000   \n",
       "406096           0.0               0.0              0.0         0.000000   \n",
       "80472            0.0               0.0              0.0         0.000000   \n",
       "462337           0.0               0.0              0.0         0.000000   \n",
       "341948           0.0               0.0              0.0         0.000000   \n",
       "...              ...               ...              ...              ...   \n",
       "91880            0.0               0.0              0.0         0.000000   \n",
       "426503           0.0               0.0              0.0         0.000000   \n",
       "420352           1.0               0.0              0.0         0.000091   \n",
       "76592            0.0               0.0              0.0         0.000000   \n",
       "444917           0.0               0.0              0.0         0.000000   \n",
       "\n",
       "        cluster_import2  cluster_area  cluster_center_distance   time_f1  \\\n",
       "498290         0.000000           0.0                      0.0  0.568065   \n",
       "406096         0.000000           0.0                      0.0  0.568065   \n",
       "80472          0.000000           0.0                      0.0  0.120537   \n",
       "462337         0.000000           0.0                      0.0  0.464723   \n",
       "341948         0.000000           0.0                      0.0  0.935016   \n",
       "...                 ...           ...                      ...       ...   \n",
       "91880          0.000000           0.0                      0.0  0.120537   \n",
       "426503         0.000000           0.0                      0.0  0.239316   \n",
       "420352         0.000183           0.0                      0.0  0.568065   \n",
       "76592          0.000000           0.0                      0.0  0.822984   \n",
       "444917         0.000000           0.0                      0.0  0.239316   \n",
       "\n",
       "         time_f2  cluster_size.1  ...  cluster_size.2  cluster_variance.2  \\\n",
       "498290  0.822984             0.0  ...             0.0                 0.0   \n",
       "406096  0.822984             0.0  ...             1.0                 0.0   \n",
       "80472   0.992709             0.0  ...             0.0                 0.0   \n",
       "462337 -0.885456             0.0  ...             0.0                 0.0   \n",
       "341948 -0.354605             0.0  ...             1.0                 0.0   \n",
       "...          ...             ...  ...             ...                 ...   \n",
       "91880   0.992709             0.0  ...             2.0                 0.0   \n",
       "426503  0.970942             0.0  ...             1.0                 0.0   \n",
       "420352  0.822984             2.0  ...             1.0                 0.0   \n",
       "76592  -0.568065             0.0  ...             0.0                 0.0   \n",
       "444917 -0.970942             0.0  ...             0.0                 0.0   \n",
       "\n",
       "        cluster_density.2  cluster_import1.2  cluster_import2.2  \\\n",
       "498290                0.0           0.000000           0.000000   \n",
       "406096                0.0           0.000083           0.000169   \n",
       "80472                 0.0           0.000000           0.000000   \n",
       "462337                0.0           0.000000           0.000000   \n",
       "341948                0.0           0.000084           0.000167   \n",
       "...                   ...                ...                ...   \n",
       "91880                 0.0           0.000170           0.000164   \n",
       "426503                0.0           0.000086           0.000156   \n",
       "420352                0.0           0.000083           0.000169   \n",
       "76592                 0.0           0.000000           0.000000   \n",
       "444917                0.0           0.000000           0.000000   \n",
       "\n",
       "        cluster_area.2  cluster_center_distance.2  time_f1.2  time_f2.2  \\\n",
       "498290             0.0                       0.00   0.748511   0.663123   \n",
       "406096             0.0                       1.00   0.748511   0.663123   \n",
       "80472              0.0                       0.00   0.970942   0.239316   \n",
       "462337             0.0                       0.00   0.239316  -0.970942   \n",
       "341948             0.0                       0.00   0.822984  -0.568065   \n",
       "...                ...                        ...        ...        ...   \n",
       "91880              0.0                       8.25   0.970942   0.239316   \n",
       "426503             0.0                       0.00   0.568065  -0.822984   \n",
       "420352             0.0                       0.00   0.748511   0.663123   \n",
       "76592              0.0                       0.00   0.239316   0.970942   \n",
       "444917             0.0                       0.00   0.464723   0.885456   \n",
       "\n",
       "        evolution_label  \n",
       "498290              0.0  \n",
       "406096              3.0  \n",
       "80472               4.0  \n",
       "462337              0.0  \n",
       "341948              0.0  \n",
       "...                 ...  \n",
       "91880               3.0  \n",
       "426503              3.0  \n",
       "420352              2.0  \n",
       "76592               0.0  \n",
       "444917              0.0  \n",
       "\n",
       "[8000 rows x 28 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>cluster_variance</th>\n",
       "      <th>cluster_density</th>\n",
       "      <th>cluster_import1</th>\n",
       "      <th>cluster_import2</th>\n",
       "      <th>cluster_area</th>\n",
       "      <th>cluster_center_distance</th>\n",
       "      <th>time_f1</th>\n",
       "      <th>time_f2</th>\n",
       "      <th>cluster_size.1</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_size.2</th>\n",
       "      <th>cluster_variance.2</th>\n",
       "      <th>cluster_density.2</th>\n",
       "      <th>cluster_import1.2</th>\n",
       "      <th>cluster_import2.2</th>\n",
       "      <th>cluster_area.2</th>\n",
       "      <th>cluster_center_distance.2</th>\n",
       "      <th>time_f1.2</th>\n",
       "      <th>time_f2.2</th>\n",
       "      <th>evolution_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498290</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406096</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80472</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462337</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.464723</td>\n",
       "      <td>-0.885456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341948</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.935016</td>\n",
       "      <td>-0.354605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91880</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120537</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>-0.822984</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420352</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.748511</td>\n",
       "      <td>0.663123</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76592</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.822984</td>\n",
       "      <td>-0.568065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>0.970942</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444917</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.239316</td>\n",
       "      <td>-0.970942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.464723</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows Ã— 28 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standardization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler = StandardScaler()\r\n",
    "\r\n",
    "train_X = scaler.fit_transform(training)[:,:-1] # all except y\r\n",
    "train_Y = training[training.columns[-1]]\r\n",
    "\r\n",
    "test_X = scaler.transform(testing)[:,:-1] # all except y\r\n",
    "test_Y = testing[testing.columns[-1]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "train_Y"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "498290    0.0\n",
       "406096    3.0\n",
       "80472     4.0\n",
       "462337    0.0\n",
       "341948    0.0\n",
       "         ... \n",
       "91880     3.0\n",
       "426503    3.0\n",
       "420352    2.0\n",
       "76592     0.0\n",
       "444917    0.0\n",
       "Name: evolution_label, Length: 8000, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(data=train_X, columns=df.columns[:-1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Balancing of Training Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "train_Y.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0    270949\n",
       "4.0     74536\n",
       "3.0     74105\n",
       "1.0     16650\n",
       "2.0     16419\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from processing import DataSampler\r\n",
    "\r\n",
    "sampler = DataSampler()\r\n",
    "train_X, train_Y = sampler.sample_median_size(train_X, train_Y, max_size=10000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "train_Y.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0    10000\n",
       "4.0    10000\n",
       "2.0    10000\n",
       "3.0    10000\n",
       "1.0    10000\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Principal Components"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "pca = PCA(n_components=10)\r\n",
    "\r\n",
    "train_Xp = pca.fit_transform(train_X)\r\n",
    "test_Xp = pca.transform(test_X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation Reports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import sklearn.metrics\r\n",
    "\r\n",
    "def print_report(clfs: list, test_Xs: list, test_Y: 'y', titles: list):\r\n",
    "    \"\"\"\r\n",
    "    Prints all reports.\r\n",
    "    :param clfs: list of classifiers to evaluate\r\n",
    "    :param test_Xs: list of test_X for the corresponding classifier at idx\r\n",
    "    :param test_Y: true classes:param titles: list of titles for the classifiers at idx\r\n",
    "    \"\"\"\r\n",
    "    for clf, test_X, title in zip(clfs, test_Xs, titles):\r\n",
    "        pred_Y = clf.predict(test_X)        \r\n",
    "        print(f\"### {title} ###\\n\", sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import pickle \r\n",
    "from pathlib import Path\r\n",
    "\r\n",
    "def export_model(model, model_name):\r\n",
    "    return\r\n",
    "    fpath = f'data/{use_case}/ml_output/{approach}/{layer_name}'\r\n",
    "    Path(fpath).mkdir(parents=True, exist_ok=True)\r\n",
    "    with open(f'{fpath}/{layer_name}_{model_name}.model', 'wb') as f:\r\n",
    "        pickle.dump(model, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive Bayes\n",
    "Working best with _Xp_\n",
    "\n",
    "49\\% accuracy and 43% f1 score\n",
    "\n",
    "Parameters: \n",
    "- priors: prior probabilities of classes, _None_\n",
    "- var\\_smoothing: \\[_0_ , 1\\]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "priors = None #np.array([19,16,16,74,74]) / (19+16+16+74+74)\r\n",
    "smoothing = 0\r\n",
    "\r\n",
    "clf = GaussianNB(priors=priors, var_smoothing=smoothing)\r\n",
    "clf.fit(train_X, train_Y)\r\n",
    "\r\n",
    "clf_p = GaussianNB(priors=priors, var_smoothing=smoothing)\r\n",
    "clf_p.fit(train_Xp, train_Y)\r\n",
    "\r\n",
    "print_report([clf, clf_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\r\n",
    "\r\n",
    "export_model(clf, 'nb_x')\r\n",
    "export_model(clf_p, 'nb_xp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Support Vector Machine\n",
    "Parameters:\n",
    "Parameters:\n",
    "- C (regularization): <1, _1_, >1, def=1\n",
    "- kernel: _linear_, rbf, poly, sigmoid, def=rbf\n",
    "- gamma (for rbf, poly, sigmoid): scale, auto, float, def=scale\n",
    "- class\\_weight: _None_, balanced, dict, def=None"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "from sklearn.svm import LinearSVC\r\n",
    "c = 1\r\n",
    "dual = False\r\n",
    "tol = 1E-4\r\n",
    "\r\n",
    "svc = LinearSVC(C=c, dual=dual, tol=tol)\r\n",
    "svc.fit(train_X, train_Y)\r\n",
    "\r\n",
    "svc_p = LinearSVC(C=c, dual=dual, tol=tol)\r\n",
    "svc_p.fit(train_Xp, train_Y)\r\n",
    "\r\n",
    "print_report([svc, svc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\r\n",
    "\r\n",
    "export_model(svc, 'svc_x')\r\n",
    "export_model(svc_p, 'svc_xp')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/itec/alercher/community-prediction/venv-gpu2/lib/python3.6/site-packages/sklearn/svm/_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "### X ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.57      0.67     67664\n",
      "         1.0       0.43      0.58      0.49      4029\n",
      "         2.0       0.32      0.48      0.38      4164\n",
      "         3.0       0.72      0.77      0.75     18652\n",
      "         4.0       0.27      0.48      0.35     18656\n",
      "\n",
      "    accuracy                           0.59    113165\n",
      "   macro avg       0.51      0.58      0.53    113165\n",
      "weighted avg       0.67      0.59      0.61    113165\n",
      "\n",
      "### Xp ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.50      0.61     67664\n",
      "         1.0       0.45      0.49      0.47      4029\n",
      "         2.0       0.30      0.46      0.36      4164\n",
      "         3.0       0.71      0.81      0.76     18652\n",
      "         4.0       0.26      0.54      0.35     18656\n",
      "\n",
      "    accuracy                           0.56    113165\n",
      "   macro avg       0.50      0.56      0.51    113165\n",
      "weighted avg       0.66      0.56      0.58    113165\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "print_report([svc, svc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.57      0.67     67664\n",
      "         1.0       0.43      0.58      0.49      4029\n",
      "         2.0       0.32      0.48      0.38      4164\n",
      "         3.0       0.72      0.77      0.75     18652\n",
      "         4.0       0.27      0.48      0.35     18656\n",
      "\n",
      "    accuracy                           0.59    113165\n",
      "   macro avg       0.51      0.58      0.53    113165\n",
      "weighted avg       0.67      0.59      0.61    113165\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NotFittedError",
     "evalue": "This LinearSVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e06b67211c0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc_p\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Xp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Xp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-3be82007dbc2>\u001b[0m in \u001b[0;36mprint_report\u001b[0;34m(clfs, test_Xs, test_Y, titles)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpred_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"### {title} ###\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/community-prediction/venv-gpu2/lib/python3.6/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \"\"\"\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/community-prediction/venv-gpu2/lib/python3.6/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \"\"\"\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/community-prediction/venv-gpu2/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/community-prediction/venv-gpu2/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LinearSVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-nearest Neighbors\n",
    "Parameters:\n",
    "- n\\_neighbors: 20\n",
    "- weights: _uniform_, distance\n",
    "- algorithm: _auto_, ball_tree, kd_tree, brute\n",
    "- leaf\\_size: 30"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "n_neighbors = 20\r\n",
    "weights = 'uniform'\r\n",
    "algo = 'auto'\r\n",
    "leaf_size = 30\r\n",
    "\r\n",
    "knnc = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\r\n",
    "knnc.fit(train_X, train_Y)\r\n",
    "\r\n",
    "knnc_p = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights,  algorithm=algo, leaf_size=leaf_size)\r\n",
    "knnc_p.fit(train_Xp, train_Y)\r\n",
    "\r\n",
    "print_report([knnc, knnc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\r\n",
    "\r\n",
    "export_model(knnc, 'knn_x')\r\n",
    "export_model(knnc_p, 'knn_xp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree\n",
    "Working well with _Xp_\n",
    "\n",
    "Parameters:\n",
    "- criterion: _gini_, entropy\n",
    "- splitter: best, _random_\n",
    "- max\\_depth: _10_, default=None\n",
    "- min\\_samples\\_leaf (to construct leaf): _1_, default=1\n",
    "- min\\_impurity\\_decrease (split if the impurity is then decreased by): _1E-5_, default=0\n",
    "- ccp\\_alpha (max allowed cost after pruning): _1E-3_, default=0 ie. nopruning\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \r\n",
    "criterion = 'gini'\r\n",
    "splitter = 'random'\r\n",
    "max_depth = 10\r\n",
    "min_samples_leaf = 1\r\n",
    "min_impurity_decrease = 1E-5 # impurity improvement needed to split\r\n",
    "ccp_alpha = 1E-3\r\n",
    "\r\n",
    "seed = 42\r\n",
    "\r\n",
    "dtc = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\r\n",
    "dtc.fit(train_X, train_Y)\r\n",
    "\r\n",
    "dtc_p = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\r\n",
    "dtc_p.fit(train_Xp, train_Y)\r\n",
    "\r\n",
    "print_report([dtc, dtc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\r\n",
    "\r\n",
    "export_model(dtc, 'dt_x')\r\n",
    "export_model(dtc_p, 'dt_xp')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest\n",
    "Parameters:\n",
    "- n\\_estimators: _100_ def=100\n",
    "- criterion: _gini_, entropy\n",
    "- max\\_depth: _None_ def=None\n",
    "- min\\_samples\\_leaf (to construct leaf): _2_ def=1\n",
    "- min\\_impurity\\_decrease (split if the impurity is then decreased by): _1E-5_ default=0\n",
    "- bootstrap (if bootstraped sample is used): _True_ def=True\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "n_estimators = 100\r\n",
    "criterion = 'gini'\r\n",
    "max_depth = None\r\n",
    "min_samples_leaf = 2\r\n",
    "min_impurity_decrease = 1E-5\r\n",
    "bootstrap=True\r\n",
    "\r\n",
    "seed = 42\r\n",
    "\r\n",
    "# rfc = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, random_state=seed)\r\n",
    "# rfc.fit(train_X, train_Y)\r\n",
    "\r\n",
    "# rfc_p = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, random_state=seed)\r\n",
    "# rfc_p.fit(train_Xp, train_Y)\r\n",
    "\r\n",
    "import pickle\r\n",
    "\r\n",
    "with open(f'data/{use_case}/ml_output/{approach}/LikesLayer.model', 'rb') as file:\r\n",
    "    likes = pickle.load(file)\r\n",
    "    \r\n",
    "with open(f'data/{use_case}/ml_output/{approach}/DislikesLayer.model', 'rb') as file:\r\n",
    "    dlikes = pickle.load(file)\r\n",
    "    \r\n",
    "with open(f'data/{use_case}/ml_output/{approach}/TrendDelayLayer.model', 'rb') as file:\r\n",
    "    trenddelay = pickle.load(file)\r\n",
    "\r\n",
    "print_report([likes, dlikes, trenddelay], [test_X, test_X, test_X], test_Y, [\"likes\", \"dislikes\", 'trenddelay'])\r\n",
    "\r\n",
    "# export_model(rfc, 'rf_x')\r\n",
    "# export_model(rfc_p, 'rf_xp')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "g:\\Arbeit\\community-prediction\\venv\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 0.24.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "g:\\Arbeit\\community-prediction\\venv\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.2 when using version 0.24.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### likes ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.45      0.58     67664\n",
      "         1.0       0.38      0.84      0.52      4029\n",
      "         2.0       0.31      0.50      0.38      4164\n",
      "         3.0       0.76      0.66      0.71     18652\n",
      "         4.0       0.27      0.63      0.38     18656\n",
      "\n",
      "    accuracy                           0.53    113165\n",
      "   macro avg       0.51      0.62      0.51    113165\n",
      "weighted avg       0.68      0.53      0.56    113165\n",
      "\n",
      "### dislikes ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.53      0.64     67664\n",
      "         1.0       0.13      0.72      0.22      4029\n",
      "         2.0       0.38      0.35      0.36      4164\n",
      "         3.0       0.76      0.23      0.35     18652\n",
      "         4.0       0.27      0.53      0.36     18656\n",
      "\n",
      "    accuracy                           0.48    113165\n",
      "   macro avg       0.47      0.47      0.39    113165\n",
      "weighted avg       0.67      0.48      0.52    113165\n",
      "\n",
      "### trenddelay ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.51      0.62     67664\n",
      "         1.0       0.13      0.80      0.22      4029\n",
      "         2.0       0.20      0.28      0.23      4164\n",
      "         3.0       0.75      0.04      0.08     18652\n",
      "         4.0       0.24      0.48      0.33     18656\n",
      "\n",
      "    accuracy                           0.43    113165\n",
      "   macro avg       0.42      0.42      0.30    113165\n",
      "weighted avg       0.64      0.43      0.45    113165\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "print_report([rfc, rfc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Boosting\n",
    "Parameters:\n",
    "- base\\_estimator: None\n",
    "- n\\_estimators: 50\n",
    "- algorithm: samme.r\n",
    "- learning\\_rate: .3\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\r\n",
    "base_estimator = None #SVC(kernel='linear')\r\n",
    "n_estimators = 50\r\n",
    "algo = 'SAMME.R'\r\n",
    "learning_rate = .3\r\n",
    "\r\n",
    "bc = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, algorithm=algo, learning_rate=learning_rate)\r\n",
    "bc.fit(train_X, train_Y)\r\n",
    "\r\n",
    "bc_p = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, algorithm=algo, learning_rate=learning_rate)\r\n",
    "bc_p.fit(train_Xp, train_Y)\r\n",
    "\r\n",
    "print_report([bc, bc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\r\n",
    "\r\n",
    "export_model(bc, 'boost_x')\r\n",
    "export_model(bc_p, 'boost_xp')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}