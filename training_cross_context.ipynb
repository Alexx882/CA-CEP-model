{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0edc7e8da127e731d54753afe8930f1420dc6ae9a13010eedc53dff7bbda352d4",
   "display_name": "Python 3.6.9  ('venv-gpu2': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "edc7e8da127e731d54753afe8930f1420dc6ae9a13010eedc53dff7bbda352d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Cross-Context Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case = 'youtube'\n",
    "layer_name = 'DislikesLayer' \n",
    "reference_layer_name = 'ViewsLayer'\n",
    "\n",
    "approach = 'cross_context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "df: DataFrame = pd.read_csv(f'data/{use_case}/ml_input/cross_context/{layer_name}_{reference_layer_name}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nWorking with: 150576 training points + 37644 test points (0.2 test ratio).\nLabel Occurrences: Total = Counter({0.0: 101228, 3.0: 28481, 4.0: 28129, 1.0: 15471, 2.0: 14911}), Training = Counter({0.0: 81021, 3.0: 22736, 4.0: 22524, 1.0: 12359, 2.0: 11936}), Test = Counter({0.0: 20207, 3.0: 5745, 4.0: 5605, 1.0: 3112, 2.0: 2975})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "def split_data(dataframe, test_dataset_frac=.2, shuffle=False) -> '(training_data, test_data)':\n",
    "    if shuffle:\n",
    "        dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    training_size = int(len(dataframe) * (1-test_dataset_frac))\n",
    "\n",
    "    train = dataframe[:training_size].reset_index(drop=True)\n",
    "    test = dataframe[training_size:].reset_index(drop=True)\n",
    "\n",
    "    y_train = train[train.columns[-1]]\n",
    "    y_test = test[test.columns[-1]]\n",
    "  \n",
    "    print(f\"\\nWorking with: {len(train)} training points + {len(test)} test points ({len(test)/(len(test)+len(train))} test ratio).\")\n",
    "    print(f\"Label Occurrences: Total = {collections.Counter(y_train.tolist() + y_test.tolist())}, \"\\\n",
    "          f\"Training = {collections.Counter(y_train)}, Test = {collections.Counter(y_test)}\")\n",
    "    # try:\n",
    "    #     print(f\"Label Majority Class: Training = {stat.mode(Y_train)}, Test = {stat.mode(Y_test)}\\n\")\n",
    "    # except stat.StatisticsError:\n",
    "    #     print(f\"Label Majority Class: no unique mode; found 2 equally common values\")\n",
    "\n",
    "    return train, test\n",
    "\n",
    "training, testing = split_data(df, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "source": [
    "## Standardization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_X = scaler.fit_transform(training)[:,:-1] # all except y\n",
    "train_Y = training[training.columns[-1]]\n",
    "\n",
    "test_X = scaler.transform(testing)[:,:-1] # all except y\n",
    "test_Y = testing[testing.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=train_X, columns=df.columns[:-1])"
   ]
  },
  {
   "source": [
    "## Balancing of Training Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0    20207\n",
       "3.0     5745\n",
       "4.0     5605\n",
       "1.0     3112\n",
       "2.0     2975\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "test_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import DataSampler\n",
    "\n",
    "sampler = DataSampler()\n",
    "train_X, train_Y = sampler.sample_median_size(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0    22524\n",
       "3.0    22524\n",
       "4.0    22524\n",
       "2.0    22524\n",
       "0.0    22524\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train_Y.value_counts()"
   ]
  },
  {
   "source": [
    "## Principal Components"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "\n",
    "train_Xp = pca.fit_transform(train_X)\n",
    "test_Xp = pca.transform(test_X)"
   ]
  },
  {
   "source": [
    "## Evaluation Reports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def print_report(clfs: list, test_Xs: list, test_Y: 'y', titles: list):\n",
    "    \"\"\"\n",
    "    Prints all reports.\n",
    "    :param clfs: list of classifiers to evaluate\n",
    "    :param test_Xs: list of test_X for the corresponding classifier at idx\n",
    "    :param test_Y: true classes\n",
    "    :param titles: list of titles for the classifiers at idx\n",
    "    \"\"\"\n",
    "    for clf, test_X, title in zip(clfs, test_Xs, titles):\n",
    "        pred_Y = clf.predict(test_X)        \n",
    "        print(f\"### {title} ###\\n\", sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "def export_model(model, model_name):\n",
    "    return\n",
    "    \n",
    "    with open(f'data/{use_case}/ml_output/{approach}/{layer_name}_{model_name}.model', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "source": [
    "# Naive Bayes\n",
    "Working best with _Xp_\n",
    "\n",
    "Parameters: \n",
    "- priors: _prior probabilities of classes_, none\n",
    "- var\\_smoothing: \\[_0_ , 1\\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.57      0.63     20207\n",
      "         1.0       0.29      0.18      0.22      3112\n",
      "         2.0       0.18      0.78      0.29      2975\n",
      "         3.0       0.19      0.14      0.16      5745\n",
      "         4.0       0.20      0.07      0.11      5605\n",
      "\n",
      "    accuracy                           0.41     37644\n",
      "   macro avg       0.31      0.35      0.28     37644\n",
      "weighted avg       0.48      0.41      0.42     37644\n",
      "\n",
      "### Xp ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.87      0.74     20207\n",
      "         1.0       0.29      0.63      0.39      3112\n",
      "         2.0       0.29      0.32      0.30      2975\n",
      "         3.0       0.00      0.00      0.00      5745\n",
      "         4.0       0.28      0.02      0.03      5605\n",
      "\n",
      "    accuracy                           0.55     37644\n",
      "   macro avg       0.30      0.37      0.29     37644\n",
      "weighted avg       0.44      0.55      0.46     37644\n",
      "\n",
      "/home/itec/alercher/community-prediction/venv-gpu2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/itec/alercher/community-prediction/venv-gpu2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/itec/alercher/community-prediction/venv-gpu2/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "priors = np.array([8,2,2,1,1]) / (8+2+2+1+1)\n",
    "smoothing = 1E-9\n",
    "\n",
    "clf = GaussianNB(priors=priors, var_smoothing=smoothing)\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "clf_p = GaussianNB(priors=priors, var_smoothing=smoothing)\n",
    "clf_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([clf, clf_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(clf, 'nb_x')\n",
    "export_model(clf_p, 'nb_xp')"
   ]
  },
  {
   "source": [
    "# Support Vector Machine\n",
    "Parameters:\n",
    "- kernel: _linear_, rbf, poly, sigmoid\n",
    "- C (regularization): <1, _1_, >1\n",
    "- class\\_weight: _None_, balanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "c = 1\n",
    "kernel = 'linear'\n",
    "\n",
    "svc = SVC(kernel='linear', C=c)\n",
    "svc.fit(train_X, train_Y)\n",
    "\n",
    "svc_p = SVC(kernel='linear', C=c)\n",
    "svc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([svc, svc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(svc, 'svc_x')\n",
    "export_model(svc_p, 'svc_xp')"
   ]
  },
  {
   "source": [
    "# K-nearest Neighbors\n",
    "Parameters:\n",
    "- n\\_neighbors: _30_\n",
    "- weights: _uniform_, distance\n",
    "- algorithm: _auto_, ball_tree, kd_tree, brute\n",
    "- leaf\\_size: _50_ (no difference)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.53      0.62     20207\n",
      "         1.0       0.36      0.49      0.42      3112\n",
      "         2.0       0.34      0.44      0.38      2975\n",
      "         3.0       0.22      0.30      0.25      5745\n",
      "         4.0       0.21      0.27      0.24      5605\n",
      "\n",
      "    accuracy                           0.45     37644\n",
      "   macro avg       0.37      0.41      0.38     37644\n",
      "weighted avg       0.52      0.45      0.47     37644\n",
      "\n",
      "### Xp ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.53      0.62     20207\n",
      "         1.0       0.36      0.49      0.42      3112\n",
      "         2.0       0.34      0.44      0.38      2975\n",
      "         3.0       0.22      0.30      0.25      5745\n",
      "         4.0       0.21      0.27      0.24      5605\n",
      "\n",
      "    accuracy                           0.45     37644\n",
      "   macro avg       0.37      0.41      0.38     37644\n",
      "weighted avg       0.51      0.45      0.47     37644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 30\n",
    "weights = 'uniform'\n",
    "algo = 'auto'\n",
    "leaf_size = 50\n",
    "\n",
    "knnc = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "knnc.fit(train_X, train_Y)\n",
    "\n",
    "knnc_p = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights,  algorithm=algo, leaf_size=leaf_size)\n",
    "knnc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([knnc, knnc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(knnc, 'knn_x')\n",
    "export_model(knnc_p, 'knn_xp')"
   ]
  },
  {
   "source": [
    "# Decision Tree\n",
    "Working well with _Xp_\n",
    "\n",
    "Parameters:\n",
    "- criterion: _gini_, entropy\n",
    "- splitter: best, _random_\n",
    "- max_depth: default=None\n",
    "- min_samples_leaf (to construct leaf): default=1\n",
    "- min_impurity_decrease (split if the impurity is then decreased by): default=0\n",
    "- ccp_alpha (max allowed cost after pruning): default=0/nopruning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n               precision    recall  f1-score   support\n\n         0.0       0.70      0.53      0.60     20207\n         1.0       0.32      0.49      0.38      3112\n         2.0       0.30      0.39      0.34      2975\n         3.0       0.20      0.28      0.23      5745\n         4.0       0.20      0.20      0.20      5605\n\n    accuracy                           0.43     37644\n   macro avg       0.34      0.38      0.35     37644\nweighted avg       0.48      0.43      0.45     37644\n\n### Xp ###\n               precision    recall  f1-score   support\n\n         0.0       0.68      0.51      0.58     20207\n         1.0       0.29      0.50      0.37      3112\n         2.0       0.25      0.34      0.29      2975\n         3.0       0.19      0.26      0.22      5745\n         4.0       0.19      0.17      0.18      5605\n\n    accuracy                           0.41     37644\n   macro avg       0.32      0.36      0.33     37644\nweighted avg       0.47      0.41      0.43     37644\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "criterion = 'entropy'\n",
    "splitter = 'random'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease = 0 # impurity improvement needed to split\n",
    "ccp_alpha = 0\n",
    "\n",
    "seed=42\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\n",
    "dtc.fit(train_X, train_Y)\n",
    "\n",
    "dtc_p = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\n",
    "dtc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([dtc, dtc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(dtc, 'dt_x')\n",
    "export_model(dtc_p, 'dt_xp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report([dtc, dtc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Random Forest\n",
    "Parameters:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.41      0.52     20207\n",
      "         1.0       0.33      0.43      0.37      3112\n",
      "         2.0       0.31      0.41      0.35      2975\n",
      "         3.0       0.20      0.31      0.24      5745\n",
      "         4.0       0.19      0.31      0.24      5605\n",
      "\n",
      "    accuracy                           0.38     37644\n",
      "   macro avg       0.35      0.37      0.34     37644\n",
      "weighted avg       0.49      0.38      0.41     37644\n",
      "\n",
      "### Xp ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.41      0.52     20207\n",
      "         1.0       0.33      0.43      0.37      3112\n",
      "         2.0       0.31      0.41      0.35      2975\n",
      "         3.0       0.20      0.31      0.24      5745\n",
      "         4.0       0.19      0.31      0.24      5605\n",
      "\n",
      "    accuracy                           0.38     37644\n",
      "   macro avg       0.35      0.37      0.35     37644\n",
      "weighted avg       0.49      0.38      0.41     37644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators = 100\n",
    "criterion = 'entropy'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease= 0\n",
    "bootstrap=True\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap)\n",
    "rfc.fit(train_X, train_Y)\n",
    "\n",
    "rfc_p = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap)\n",
    "rfc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([rfc, rfc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(rfc, 'rf_x')\n",
    "export_model(rfc_p, 'rf_xp')"
   ]
  },
  {
   "source": [
    "# Boosting\n",
    "50% accuracy, 51% f1\n",
    "\n",
    "Parameters:\n",
    "- base\\_estimator: None\n",
    "- n\\_estimators: 50\n",
    "- algorithm: samme.r\n",
    "- learning\\_rate: .3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.33      0.46     20207\n",
      "         1.0       0.17      0.20      0.18      3112\n",
      "         2.0       0.31      0.45      0.37      2975\n",
      "         3.0       0.20      0.41      0.27      5745\n",
      "         4.0       0.17      0.28      0.22      5605\n",
      "\n",
      "    accuracy                           0.33     37644\n",
      "   macro avg       0.32      0.33      0.30     37644\n",
      "weighted avg       0.50      0.33      0.37     37644\n",
      "\n",
      "### Xp ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.31      0.44     20207\n",
      "         1.0       0.20      0.53      0.29      3112\n",
      "         2.0       0.23      0.42      0.30      2975\n",
      "         3.0       0.20      0.28      0.24      5745\n",
      "         4.0       0.17      0.25      0.20      5605\n",
      "\n",
      "    accuracy                           0.32     37644\n",
      "   macro avg       0.31      0.36      0.29     37644\n",
      "weighted avg       0.50      0.32      0.35     37644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_estimator = SVC(kernel='linear')\n",
    "n_estimators= 50\n",
    "algo = 'SAMME'\n",
    "learning_rate = .3\n",
    "\n",
    "bc = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, algorithm=algo, learning_rate=learning_rate)\n",
    "bc.fit(train_X, train_Y)\n",
    "\n",
    "bc_p = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, algorithm=algo, learning_rate=learning_rate)\n",
    "bc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([bc, bc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(bc, 'boost_x')\n",
    "export_model(bc_p, 'boost_xp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.66      0.69     20207\n",
      "         1.0       0.45      0.55      0.49      3112\n",
      "         2.0       0.31      0.34      0.32      2975\n",
      "         3.0       0.26      0.17      0.21      5745\n",
      "         4.0       0.23      0.33      0.27      5605\n",
      "\n",
      "    accuracy                           0.50     37644\n",
      "   macro avg       0.39      0.41      0.40     37644\n",
      "weighted avg       0.52      0.50      0.51     37644\n",
      "\n",
      "### Xp ###\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.66      0.69     20207\n",
      "         1.0       0.41      0.46      0.43      3112\n",
      "         2.0       0.33      0.43      0.37      2975\n",
      "         3.0       0.28      0.08      0.13      5745\n",
      "         4.0       0.22      0.40      0.29      5605\n",
      "\n",
      "    accuracy                           0.50     37644\n",
      "   macro avg       0.39      0.41      0.38     37644\n",
      "weighted avg       0.52      0.50      0.50     37644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_report([bc, bc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  }
 ]
}