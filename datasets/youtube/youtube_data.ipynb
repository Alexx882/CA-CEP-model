{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0ac79ad19892b6e891e8d97ca5fdbb2e2457e6e4ba8b10fb20aa9e37280e031f3",
   "display_name": "Python 3.7.8  ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac79ad19892b6e891e8d97ca5fdbb2e2457e6e4ba8b10fb20aa9e37280e031f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Youtube trends \n",
    "https://www.kaggle.com/datasnaek/youtube-new"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = ['CA', 'DE', 'FR', 'GB', 'IN', 'JP', 'KR', 'MX', 'RU', 'US']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "data = {}\n",
    "\n",
    "for country_code in country_codes:\n",
    "    # load videos per country\n",
    "    print(country_code)\n",
    "\n",
    "\n",
    "    category_fn = f'raw/{country_code}_category_id.json'\n",
    "\n",
    "    with open(category_fn, 'r') as f:\n",
    "        cats = json.loads(f.read())\n",
    "        categories[country_code] = {entry['id'] : entry['snippet']['title'] for entry in cats['items']}\n",
    "\n",
    "    \n",
    "    video_fn = f'raw/{country_code}videos.csv'\n",
    "\n",
    "    try:\n",
    "        data[country_code]: DataFrame = pd.read_csv(video_fn, encoding='utf-8') \n",
    "    except Exception as e:\n",
    "        print(f\"Error for {country_code} : {e}\")\n"
   ]
  },
  {
   "source": [
    "## Prepare categories"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one large map for all global categories as they are just \n",
    "global_cats = {}\n",
    "\n",
    "for _, cats in categories.items():\n",
    "    for cat in cats.items():\n",
    "        if cat[0] not in global_cats: \n",
    "            global_cats[cat[0]] = []\n",
    "\n",
    "        global_cats[cat[0]].append(cat[1])\n",
    "\n",
    "assert len({key : len(set(val)) for key, val in global_cats.items() if len(set(val)) > 1}) == 0, 'NOT unique and same names for categories for all countries'\n",
    "\n",
    "global_categories = {key : val[0] for key, val in global_cats.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('categories.json', 'w') as file:\n",
    "    file.write(json.dumps(global_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_categories"
   ]
  },
  {
   "source": [
    "## Prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add country info and category names\n",
    "for i, cc in enumerate(country_codes):\n",
    "    data[cc]['country_code'] = cc\n",
    "    data[cc]['country_id'] = i\n",
    "\n",
    "    data[cc]['category_name'] = data[cc].apply(lambda row: global_categories[str(row['category_id'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['JP'].tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum_ = 0\n",
    "for cc in country_codes:\n",
    "    columns = data[cc].columns\n",
    "    print(f\"{cc} ({len(columns)}) ({data[cc].size}): {columns}\")\n",
    "    sum_ += len(data[cc])\n",
    "\n",
    "print(sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat(list(data.values()), ignore_index=True, join='inner')\n",
    "dfs"
   ]
  },
  {
   "source": [
    "dfs.to_csv('videos.csv')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}