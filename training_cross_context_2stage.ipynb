{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0edc7e8da127e731d54753afe8930f1420dc6ae9a13010eedc53dff7bbda352d4",
   "display_name": "Python 3.6.9 64-bit ('venv-gpu2': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "edc7e8da127e731d54753afe8930f1420dc6ae9a13010eedc53dff7bbda352d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Cross-Context Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case = 'youtube'\n",
    "layer_name = 'TrendDelayLayer' \n",
    "reference_layer_name = 'ViewsLayer'\n",
    "\n",
    "approach = 'cross_context_2stage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "df: DataFrame = pd.read_csv(f'data/{use_case}/ml_input/cross_context/{layer_name}_{reference_layer_name}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nWorking with: 3504 training points + 876 test points (0.2 test ratio).\nLabel Occurrences: Total = Counter({-1.0: 2625, 1.0: 540, 2.0: 493, 3.0: 332, 4.0: 304, 0.0: 86}), Training = Counter({-1.0: 2127, 1.0: 430, 2.0: 374, 3.0: 262, 4.0: 240, 0.0: 71}), Test = Counter({-1.0: 498, 2.0: 119, 1.0: 110, 3.0: 70, 4.0: 64, 0.0: 15})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "def split_data(dataframe, test_dataset_frac=.2, shuffle=False) -> '(training_data, test_data)':\n",
    "    if shuffle:\n",
    "        dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    training_size = int(len(dataframe) * (1-test_dataset_frac))\n",
    "\n",
    "    train = dataframe[:training_size].reset_index(drop=True)\n",
    "    test = dataframe[training_size:].reset_index(drop=True)\n",
    "\n",
    "    y_train = train[train.columns[-1]]\n",
    "    y_test = test[test.columns[-1]]\n",
    "  \n",
    "    print(f\"\\nWorking with: {len(train)} training points + {len(test)} test points ({len(test)/(len(test)+len(train))} test ratio).\")\n",
    "    print(f\"Label Occurrences: Total = {collections.Counter(y_train.tolist() + y_test.tolist())}, \"\\\n",
    "          f\"Training = {collections.Counter(y_train)}, Test = {collections.Counter(y_test)}\")\n",
    "\n",
    "    return train, test\n",
    "\n",
    "training, testing = split_data(df, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_empty_community_class(df):\n",
    "    '''Removes evolution_label -1 from dataset indicating the community stays empty.'''\n",
    "    # res = df.loc[df['evolution_label'] != -1.0]\n",
    "    # res = res.reset_index(drop=True)\n",
    "    # return res\n",
    "    df['evolution_label'] = df['evolution_label'].replace(-1.0, 0)\n",
    "    return df\n",
    "\n",
    "training = remove_empty_community_class(training)\n",
    "testing = remove_empty_community_class(testing)"
   ]
  },
  {
   "source": [
    "## Standardization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_X = scaler.fit_transform(training)[:,:-1] # all except y\n",
    "train_Y = training[training.columns[-1]]\n",
    "\n",
    "test_X = scaler.transform(testing)[:,:-1] # all except y\n",
    "test_Y = testing[testing.columns[-1]]"
   ]
  },
  {
   "source": [
    "## Balancing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import DataSampler\n",
    "\n",
    "sampler = DataSampler()\n",
    "train_X, train_Y = sampler.sample_median_size(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=train_X, columns=df.columns[:-1])"
   ]
  },
  {
   "source": [
    "## Two-stage approach\n",
    "### 1. Stage: Change Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_stage1_data(X, y: pd.Series) -> ('X', 'y'):\n",
    "    '''Simplify dataset classes to 0 -> 0, other -> 1.'''\n",
    "    y_stg1 = y.apply(lambda elem: 0 if elem == 0 else 1)\n",
    "    return X, y_stg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    2198\n",
       "1    1306\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "train_X_stg1, train_Y_stg1 = prepare_stage1_data(train_X, train_Y)\n",
    "train_Y_stg1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    513\n",
       "1    363\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "test_X_stg1, test_Y_stg1 = prepare_stage1_data(test_X, test_Y)\n",
    "test_Y_stg1.value_counts()"
   ]
  },
  {
   "source": [
    "### 2. Stage: Change Type Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_stage2_data(X, y, columns) -> ('X', 'y'):\n",
    "    '''Remove class 0 from dataset.'''\n",
    "    xy = pd.DataFrame(data=X, columns=columns)\n",
    "    xy['evolution_label'] = y\n",
    "\n",
    "    # remove class 0\n",
    "    tmp = xy.loc[xy['evolution_label'] != 0.0].reset_index(drop=True)\n",
    "    X_stg2 = tmp[tmp.columns[:-1]]\n",
    "    Y_stg2 = tmp[tmp.columns[-1]]\n",
    "    \n",
    "    return X_stg2, Y_stg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0    430\n",
       "2.0    374\n",
       "3.0    262\n",
       "4.0    240\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "train_X_stg2, train_Y_stg2 = prepare_stage2_data(train_X, train_Y, columns=training.columns[:-1])\n",
    "train_Y_stg2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0    119\n",
       "1.0    110\n",
       "3.0     70\n",
       "4.0     64\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "test_X_stg2, test_Y_stg2 = prepare_stage2_data(test_X, test_Y, columns=testing.columns[:-1])\n",
    "test_Y_stg2.value_counts()"
   ]
  },
  {
   "source": [
    "## Balancing of Training Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    2198\n",
       "1    1306\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "train_Y_stg1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0    430\n",
       "2.0    374\n",
       "3.0    262\n",
       "4.0    240\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "train_Y_stg2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import DataSampler\n",
    "sampler = DataSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    1000\n",
       "0    1000\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "# balancing by downsampling\n",
    "\n",
    "train_X_stg1, train_Y_stg1 = sampler.sample_fixed_size(train_X_stg1, train_Y_stg1, size=1000)\n",
    "train_Y_stg1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4.0    300\n",
       "3.0    300\n",
       "2.0    300\n",
       "1.0    300\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# balancing by downsampling \n",
    "\n",
    "train_X_stg2, train_Y_stg2 = sampler.sample_fixed_size(train_X_stg2, train_Y_stg2, size=300)\n",
    "train_Y_stg2.value_counts()"
   ]
  },
  {
   "source": [
    "## Principal Components"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "pca.fit(train_X)\n",
    "test_Xp = pca.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca1 = PCA(n_components=8)\n",
    "train_Xp_stg1 = pca1.fit_transform(train_X_stg1)\n",
    "test_Xp_stg1 = pca1.transform(test_X_stg1)\n",
    "\n",
    "pca2 = PCA(n_components=8)\n",
    "train_Xp_stg2 = pca2.fit_transform(train_X_stg2)\n",
    "test_Xp_stg2 = pca2.transform(test_X_stg2)"
   ]
  },
  {
   "source": [
    "## Evaluation Reports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def print_report(clfs: list, test_Xs: list, test_Y: 'y', titles: list):\n",
    "    \"\"\"\n",
    "    Prints all reports.\n",
    "    :param clfs: list of classifiers to evaluate\n",
    "    :param test_Xs: list of test_X for the corresponding classifier at idx\n",
    "    :param test_Y: true classes\n",
    "    :param titles: list of titles for the classifiers at idx\n",
    "    \"\"\"\n",
    "    for clf, test_X, title in zip(clfs, test_Xs, titles):\n",
    "        pred_Y = clf.predict(test_X)        \n",
    "        print(f\"### {title} ###\\n\", sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def export_model(model, model_name):    \n",
    "    fpath = f'data/{use_case}/ml_output/{approach}/{layer_name}'\n",
    "    Path(fpath).mkdir(parents=True, exist_ok=True)\n",
    "    with open(f'{fpath}/{layer_name}_{reference_layer_name}_{model_name}.model', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(clf1, clf2, test_X) -> 'pred_y':\n",
    "    '''Runs the two-stage approach by predicting first with clf1 then clf2.'''\n",
    "    # STG 1\n",
    "    pred_Y_stg1 = clf1.predict(test_X)   \n",
    "\n",
    "    # merge original X with predicted change Y1\n",
    "    test_xy = pd.DataFrame(data=test_X, columns=testing.columns[:-1])\n",
    "    test_xy['evolution_label'] = pred_Y_stg1\n",
    "    \n",
    "    # create new test set with from all predicted change=1\n",
    "    test_xy_stg2 = test_xy.loc[test_xy['evolution_label'] == 1.0]\n",
    "    test_X_stg2 = test_xy_stg2[test_xy_stg2.columns[:-1]]\n",
    "\n",
    "    if len(test_X_stg2) > 0:\n",
    "        # STG 2\n",
    "        pred_Y_stg2 = clf2.predict(test_X_stg2)\n",
    "\n",
    "        # merge stg2 X with predicted change type Y2\n",
    "        test_xy_stg2 = test_X_stg2\n",
    "        test_xy_stg2['evolution_label'] = pred_Y_stg2\n",
    "\n",
    "        # merge results based on original index (pred class 0 stays 0)\n",
    "        test_xy['evolution_label'].update(test_xy_stg2['evolution_label'])\n",
    "        \n",
    "    pred_Y = test_xy['evolution_label']\n",
    "\n",
    "    return pred_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Xp, train_Y = train_X_stg1, train_Xp_stg1, train_Y_stg1\n",
    "test_X, test_Xp, test_Y = test_X_stg1, test_Xp_stg1, test_Y_stg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Xp, train_Y = train_X_stg2, train_Xp_stg2, train_Y_stg2\n",
    "test_X, test_Xp, test_Y = test_X_stg2, test_Xp_stg2, test_Y_stg2"
   ]
  },
  {
   "source": [
    "# Naive Bayes\n",
    "Working best with _Xp_\n",
    "\n",
    "Stage 1: 68% accuracy/f1 score (Xp) \n",
    "Parameters: \n",
    "- priors: prior probabilities of classes, _None_\n",
    "- var\\_smoothing: \\[0, 1\\] _1E-9_\n",
    "\n",
    "Stage 2: 40% accuracy, 38% f1 with Xp\n",
    "Parameters: \n",
    "- None\n",
    "- 1E-9"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "priors = np.array([53,27]) / (53+27)\n",
    "smoothing = 1E-9\n",
    "\n",
    "clf1 = GaussianNB(priors=priors, var_smoothing=smoothing)\n",
    "clf1.fit(train_X_stg1, train_Y_stg1)\n",
    "export_model(clf1, 'nb1_x')\n",
    "\n",
    "# clf1_p = GaussianNB(priors=priors, var_smoothing=smoothing)\n",
    "# clf1_p.fit(train_Xp_stg1, train_Y_stg1)\n",
    "# export_model(clf1_p, 'nb1_xp')\n",
    "\n",
    "# print_report([clf, clf_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "priors = None \n",
    "smoothing = 1E-9\n",
    "\n",
    "clf2 = GaussianNB(priors=priors, var_smoothing=smoothing)\n",
    "clf2.fit(train_X_stg2, train_Y_stg2)\n",
    "export_model(clf2, 'nb2_x')\n",
    "\n",
    "# clf2_p = GaussianNB(priors=priors, var_smoothing=smoothing)\n",
    "# clf2_p.fit(train_Xp_stg2, train_Y_stg2)\n",
    "# export_model(clf2_p, 'nb2_xp')\n",
    "\n",
    "# print_report([clf, clf_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NB:                precision    recall  f1-score   support\n\n         0.0       0.79      0.65      0.71       513\n         1.0       0.33      0.12      0.17       110\n         2.0       0.39      0.36      0.38       119\n         3.0       0.28      0.16      0.20        70\n         4.0       0.18      0.73      0.29        64\n\n    accuracy                           0.51       876\n   macro avg       0.39      0.40      0.35       876\nweighted avg       0.59      0.51      0.53       876\n\n"
     ]
    }
   ],
   "source": [
    "pred_Y = predict_all(clf1, clf2, test_X)\n",
    "print('NB: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))\n",
    "\n",
    "# pred_Y = predict_all(clf1_p, clf2_p, test_X, pca=True)\n",
    "# print('NB Xp: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "# Support Vector Machine\n",
    "Stage 1: 69% accuracy/f1\n",
    "Parameters:\n",
    "- C (regularization): <1, _1_, >1, def=1\n",
    "- kernel: _linear_, rbf, poly, sigmoid, def=rbf\n",
    "- gamma (for rbf, poly, sigmoid): scale, auto, float, def=scale\n",
    "- class\\_weight: _None_, balanced, dict, def=None\n",
    "\n",
    "Stage 2: 44% accuracy/f1\n",
    "Parameters:\n",
    "- 10\n",
    "- rbf\n",
    "- scale\n",
    "- None\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "c = 1\n",
    "kernel = 'linear'\n",
    "gamma = 'scale'\n",
    "weights = None\n",
    "\n",
    "svc1 = LinearSVC(C=c, dual=False)\n",
    "svc1.fit(train_X_stg1, train_Y_stg1)\n",
    "export_model(svc1, 'svc1_x')\n",
    "\n",
    "# svc1_p = SVC(C=c, kernel=kernel, gamma=gamma, class_weight=weights)\n",
    "# svc1_p.fit(train_Xp_stg1, train_Y_stg1)\n",
    "# export_model(svc1_p, 'svc1_xp')\n",
    "\n",
    "# print('report.')\n",
    "# print_report([svc, svc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "c = 10\n",
    "kernel = 'rbf'\n",
    "gamma = 'scale'\n",
    "weights = None\n",
    "\n",
    "svc2 = SVC(C=c, kernel=kernel, gamma=gamma)# dual=False)\n",
    "svc2.fit(train_X_stg2, train_Y_stg2)\n",
    "export_model(svc2, 'svc2_x')\n",
    "\n",
    "# svc2_p = SVC(C=c, kernel=kernel, gamma=gamma, class_weight=weights)\n",
    "# svc2_p.fit(train_Xp_stg2, train_Y_stg2)\n",
    "# export_model(svc2_p, 'svc2_xp')\n",
    "\n",
    "# print('report.')\n",
    "# print_report([svc, svc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC:                precision    recall  f1-score   support\n\n         0.0       0.87      0.78      0.82       513\n         1.0       0.56      0.40      0.47       110\n         2.0       0.48      0.61      0.54       119\n         3.0       0.36      0.36      0.36        70\n         4.0       0.28      0.52      0.36        64\n\n    accuracy                           0.65       876\n   macro avg       0.51      0.53      0.51       876\nweighted avg       0.69      0.65      0.67       876\n\n"
     ]
    }
   ],
   "source": [
    "pred_Y = predict_all(svc1, svc2, test_X)\n",
    "print('SVC: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))\n",
    "\n",
    "# pred_Y = predict_all(svc1_p, svc2_p, test_X)\n",
    "# print('SVC Xp: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "# K-nearest Neighbors\n",
    "\n",
    "Stage 1: 70% accuracy, 70% f1 score\n",
    "Parameters:\n",
    "- n\\_neighbors: _30_\n",
    "- weights: _uniform_, distance\n",
    "- algorithm: _auto_, ball_tree, kd_tree, brute\n",
    "- leaf\\_size: _50_ (no difference)\n",
    "\n",
    "Stage 2: 46% accuracy/f1 \n",
    "Parameters:\n",
    "- _20_\n",
    "- uniform\n",
    "- auto\n",
    "- _30_\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 30\n",
    "weights = 'uniform'\n",
    "algo = 'auto'\n",
    "leaf_size = 50\n",
    "\n",
    "knnc1 = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "knnc1.fit(train_X_stg1, train_Y_stg1)\n",
    "export_model(knnc1, 'knn1_x')\n",
    "\n",
    "# knnc1_p = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "# knnc1_p.fit(train_Xp_stg1, train_Y_stg1)\n",
    "# export_model(knnc1_p, 'knn1_xp')\n",
    "\n",
    "# print_report([knnc1, knnc1_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 20\n",
    "weights = 'uniform'\n",
    "algo = 'auto'\n",
    "leaf_size = 30\n",
    "\n",
    "knnc2 = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "knnc2.fit(train_X_stg2, train_Y_stg2)\n",
    "export_model(knnc2, 'knn2_x')\n",
    "\n",
    "# knnc2_p = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "# knnc2_p.fit(train_Xp_stg2, train_Y_stg2)\n",
    "# export_model(knnc2_p, 'knn2_xp')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_report([knnc2], [test_X_stg2], test_Y_stg2, [\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN:                precision    recall  f1-score   support\n\n         0.0       0.89      0.76      0.82       513\n         1.0       0.50      0.40      0.44       110\n         2.0       0.47      0.53      0.50       119\n         3.0       0.27      0.44      0.33        70\n         4.0       0.31      0.48      0.38        64\n\n    accuracy                           0.64       876\n   macro avg       0.49      0.52      0.49       876\nweighted avg       0.69      0.64      0.66       876\n\n"
     ]
    }
   ],
   "source": [
    "pred_Y = predict_all(knnc1, knnc2, test_X)\n",
    "print('KNN: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))\n",
    "\n",
    "# pred_Y = predict_all(knnc1_p, knnc2_p, test_X, pca=True)\n",
    "# print('KNN Xp: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "# Decision Tree\n",
    "Working well with _Xp_\n",
    "\n",
    "Stage 1: 69% accuracy/f1 with Xp\n",
    "Parameters:\n",
    "- criterion: _gini_, entropy\n",
    "- splitter: best, _random_\n",
    "- max\\_depth: _None_ default=None\n",
    "- min\\_samples\\_leaf (to construct leaf): _2_ default=1\n",
    "- min\\_impurity\\_decrease (split if the impurity is then decreased by): _0_ default=0\n",
    "- ccp\\_alpha (max allowed cost after pruning): _1E-2_ default=0/nopruning\n",
    "\n",
    "Stage 2: 43% accuracy/f1 with X\n",
    "Parameters:\n",
    "- gini\n",
    "- random\n",
    "- None\n",
    "- 2\n",
    "- 0\n",
    "- _0_\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "criterion = 'gini'\n",
    "splitter = 'best'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease = 0 # impurity improvement needed to split\n",
    "ccp_alpha = 1E-2\n",
    "\n",
    "seed=42\n",
    "\n",
    "dtc1 = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\n",
    "dtc1.fit(train_X_stg1, train_Y_stg1)\n",
    "export_model(dtc1, 'dt1_x')\n",
    "\n",
    "# dtc1_p = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\n",
    "# dtc1_p.fit(train_Xp_stg1, train_Y_stg1)\n",
    "# export_model(dtc1_p, 'dt1_xp')\n",
    "\n",
    "# print_report([dtc, dtc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "criterion = 'gini'\n",
    "splitter = 'random'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease = 0 # impurity improvement needed to split\n",
    "ccp_alpha = 0\n",
    "\n",
    "seed=42\n",
    "\n",
    "dtc2 = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\n",
    "dtc2.fit(train_X_stg2, train_Y_stg2)\n",
    "export_model(dtc2, 'dt2_x')\n",
    "\n",
    "# dtc2_p = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\n",
    "# dtc2_p.fit(train_Xp_stg2, train_Y_stg2)\n",
    "# export_model(dtc2_p, 'dt2_xp')\n",
    "\n",
    "# print_report([dtc, dtc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DT:                precision    recall  f1-score   support\n\n         0.0       0.79      0.96      0.87       513\n         1.0       0.69      0.70      0.69       110\n         2.0       0.65      0.54      0.59       119\n         3.0       0.33      0.11      0.17        70\n         4.0       0.26      0.09      0.14        64\n\n    accuracy                           0.74       876\n   macro avg       0.55      0.48      0.49       876\nweighted avg       0.68      0.74      0.70       876\n\n"
     ]
    }
   ],
   "source": [
    "pred_Y = predict_all(dtc1, dtc2, test_X)\n",
    "print('DT: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))\n",
    "\n",
    "# pred_Y = predict_all(dtc1_p, dtc2_p, test_X, pca=True)\n",
    "# print('DT Xp: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "# Random Forest\n",
    "Stage 1: 69% accuracy/f1\n",
    "Parameters:\n",
    "- n\\_estimators: _100_ def=100\n",
    "- criterion: _gini_, entropy\n",
    "- max\\_depth: _None_ def=None\n",
    "- min\\_samples\\_leaf (to construct leaf): _2_ def=1\n",
    "- min\\_impurity\\_decrease (split if the impurity is then decreased by): _1E-2_ default=0\n",
    "- bootstrap (if bootstraped sample is used): _True_ def=True\n",
    "\n",
    "Stage 2: 44% accuracy/f1\n",
    "Parameters:\n",
    "- 100\n",
    "- _entropy_\n",
    "- None\n",
    "- 2\n",
    "- _0_\n",
    "- True\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators = 100\n",
    "criterion = 'gini'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease = 1E-2\n",
    "bootstrap=True\n",
    "\n",
    "seed=42\n",
    "\n",
    "rfc1 = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, random_state=seed)\n",
    "rfc1.fit(train_X_stg1, train_Y_stg1)\n",
    "export_model(rfc1, 'rf1_x')\n",
    "\n",
    "# rfc1_p = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, random_state=seed)\n",
    "# rfc1_p.fit(train_Xp_stg1, train_Y_stg1)\n",
    "# export_model(rfc1_p, 'rf1_xp')\n",
    "\n",
    "# print_report([rfc, rfc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators = 100\n",
    "criterion = 'entropy'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease = 0\n",
    "bootstrap=True\n",
    "\n",
    "seed=42\n",
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, random_state=seed)\n",
    "rfc2.fit(train_X_stg2, train_Y_stg2)\n",
    "export_model(rfc2, 'rf2_x')\n",
    "\n",
    "# rfc2_p = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, random_state=seed)\n",
    "# rfc2_p.fit(train_Xp_stg2, train_Y_stg2)\n",
    "# export_model(rfc2_p, 'rf2_xp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n               precision    recall  f1-score   support\n\n         1.0       0.03      0.24      0.05      1624\n         2.0       0.03      0.25      0.05      1666\n         3.0       0.50      0.30      0.38     31975\n         4.0       0.49      0.28      0.36     31408\n\n    accuracy                           0.29     66673\n   macro avg       0.26      0.27      0.21     66673\nweighted avg       0.47      0.29      0.35     66673\n\n"
     ]
    }
   ],
   "source": [
    "# print_report([rfc2], [test_X_stg2], test_Y_stg2, [\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RF:                precision    recall  f1-score   support\n\n         0.0       0.94      0.68      0.79       513\n         1.0       0.68      0.59      0.63       110\n         2.0       0.60      0.68      0.64       119\n         3.0       0.27      0.54      0.36        70\n         4.0       0.19      0.41      0.25        64\n\n    accuracy                           0.64       876\n   macro avg       0.54      0.58      0.54       876\nweighted avg       0.76      0.64      0.68       876\n\n"
     ]
    }
   ],
   "source": [
    "pred_Y = predict_all(rfc1, rfc2, test_X)\n",
    "print('RF: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))\n",
    "\n",
    "# pred_Y = predict_all(rfc1_p, rfc2_p, test_X, pca=True)\n",
    "# print('DT Xp: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "# Boosting\n",
    "Stage 1: 71% accuracy/f1\n",
    "Parameters:\n",
    "- base\\_estimator: object, _None(DT)_\n",
    "- n\\_estimators: _50_ def=50\n",
    "- learning\\_rate: _1_ def=1.0\n",
    "- algorithm: SAMME, _SAMME.R_\n",
    "\n",
    "Stage 2: 46% accuracy, 45% f1\n",
    "Parameters:\n",
    "- None\n",
    "- 50\n",
    "- 1\n",
    "- SAMME.R\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_estimator = None\n",
    "n_estimators= 50\n",
    "learning_rate = 1\n",
    "algo = 'SAMME.R'\n",
    "\n",
    "seed=42\n",
    "\n",
    "bc1 = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "bc1.fit(train_X_stg1, train_Y_stg1)\n",
    "export_model(bc1, 'boost1_x')\n",
    "\n",
    "# bc1_p = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "# bc1_p.fit(train_Xp_stg1, train_Y_stg1)\n",
    "# export_model(bc1_p, 'boost1_xp')\n",
    "\n",
    "# print_report([bc, bc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_estimator = None\n",
    "n_estimators= 50\n",
    "learning_rate = 1\n",
    "algo = 'SAMME.R'\n",
    "\n",
    "seed=42\n",
    "\n",
    "bc2 = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "bc2.fit(train_X_stg2, train_Y_stg2)\n",
    "export_model(bc2, 'boost2_x')\n",
    "\n",
    "# bc2_p = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "# bc2_p.fit(train_Xp_stg2, train_Y_stg2)\n",
    "# export_model(bc2_p, 'boost2_xp')\n",
    "\n",
    "# print_report([bc, bc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "B:                precision    recall  f1-score   support\n\n         0.0       0.86      0.83      0.84       513\n         1.0       0.54      0.75      0.63       110\n         2.0       0.54      0.27      0.36       119\n         3.0       0.30      0.27      0.28        70\n         4.0       0.26      0.44      0.33        64\n\n    accuracy                           0.67       876\n   macro avg       0.50      0.51      0.49       876\nweighted avg       0.69      0.67      0.67       876\n\n"
     ]
    }
   ],
   "source": [
    "pred_Y = predict_all(bc1, bc2, test_X)\n",
    "print('B: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))\n",
    "\n",
    "# pred_Y = predict_all(bc1_p, bc2_p, test_X, pca=True)\n",
    "# print('DT Xp: ', sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "# Pipeline Approach\n",
    "Pipeline from best classifier for each stage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pipeline with KNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 30\n",
    "weights = 'uniform'\n",
    "algo = 'auto'\n",
    "leaf_size = 50\n",
    "\n",
    "knnc1 = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "knnc1.fit(train_X_stg1, train_Y_stg1)\n",
    "\n",
    "print_report([knnc1], [test_X_stg1], test_Y_stg1, [\"stg1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 20\n",
    "weights = 'uniform'\n",
    "algo = 'auto'\n",
    "leaf_size = 30\n",
    "\n",
    "knnc2 = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights,  algorithm=algo, leaf_size=leaf_size)\n",
    "knnc2.fit(train_X_stg2, train_Y_stg2)\n",
    "\n",
    "print_report([knnc2], [test_X_stg2], test_Y_stg2, [\"stg2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = predict_all(knnc1, knnc2, test_X)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "## Pipeline with Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_estimator = None\n",
    "n_estimators= 50\n",
    "learning_rate = 1\n",
    "algo = 'SAMME.R'\n",
    "\n",
    "seed=42\n",
    "\n",
    "bc1 = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "bc1.fit(train_X_stg1, train_Y_stg1)\n",
    "\n",
    "bc2 = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "bc2.fit(train_X_stg2, train_Y_stg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = predict_all(bc1, bc2, test_X)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "## Final Decision: KNN then Boosting(DT)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         0.0       0.89      0.76      0.82       513\n         1.0       0.56      0.40      0.47       110\n         2.0       0.49      0.61      0.54       119\n         3.0       0.30      0.43      0.35        70\n         4.0       0.32      0.55      0.40        64\n\n    accuracy                           0.65       876\n   macro avg       0.51      0.55      0.52       876\nweighted avg       0.70      0.65      0.67       876\n\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         0.0       0.94      0.68      0.79       513\n         1.0       0.68      0.59      0.63       110\n         2.0       0.60      0.68      0.64       119\n         3.0       0.27      0.54      0.36        70\n         4.0       0.19      0.41      0.25        64\n\n    accuracy                           0.64       876\n   macro avg       0.54      0.58      0.54       876\nweighted avg       0.76      0.64      0.68       876\n\n"
     ]
    }
   ],
   "source": [
    "pred_Y = predict_all(rfc1, rfc2, test_X)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  }
 ]
}