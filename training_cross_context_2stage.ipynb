{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0edc7e8da127e731d54753afe8930f1420dc6ae9a13010eedc53dff7bbda352d4",
   "display_name": "Python 3.6.9  ('venv-gpu2': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "edc7e8da127e731d54753afe8930f1420dc6ae9a13010eedc53dff7bbda352d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Cross-Context Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case = 'youtube'\n",
    "layer_name = 'ViewsLayer' \n",
    "reference_layer_name = 'CountryLayer'\n",
    "\n",
    "approach = 'cross_context'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/itec/alercher/community-prediction/venv-gpu2/lib/python3.6/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "df: DataFrame = pd.read_csv(f'data/{use_case}/ml_input/cross_context/{layer_name}_{reference_layer_name}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "source": [
    "# Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nWorking with: 801936 training points + 200484 test points (0.2 test ratio).\nLabel Occurrences: Total = Counter({0.0: 668685, 3.0: 160491, 4.0: 156733, 1.0: 8279, 2.0: 8232}), Training = Counter({0.0: 535042, 3.0: 128236, 4.0: 125467, 1.0: 6619, 2.0: 6572}), Test = Counter({0.0: 133643, 3.0: 32255, 4.0: 31266, 1.0: 1660, 2.0: 1660})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "def split_data(dataframe, test_dataset_frac=.2, shuffle=False) -> '(training_data, test_data)':\n",
    "    if shuffle:\n",
    "        dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    training_size = int(len(dataframe) * (1-test_dataset_frac))\n",
    "\n",
    "    train = dataframe[:training_size].reset_index(drop=True)\n",
    "    test = dataframe[training_size:].reset_index(drop=True)\n",
    "\n",
    "    y_train = train[train.columns[-1]]\n",
    "    y_test = test[test.columns[-1]]\n",
    "  \n",
    "    print(f\"\\nWorking with: {len(train)} training points + {len(test)} test points ({len(test)/(len(test)+len(train))} test ratio).\")\n",
    "    print(f\"Label Occurrences: Total = {collections.Counter(y_train.tolist() + y_test.tolist())}, \"\\\n",
    "          f\"Training = {collections.Counter(y_train)}, Test = {collections.Counter(y_test)}\")\n",
    "\n",
    "    return train, test\n",
    "\n",
    "training, testing = split_data(df, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "source": [
    "## Standardization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_X = scaler.fit_transform(training)[:,:-1] # all except y\n",
    "train_Y = training[training.columns[-1]]\n",
    "\n",
    "test_X = scaler.transform(testing)[:,:-1] # all except y\n",
    "test_Y = testing[testing.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0    133643\n",
       "3.0     32255\n",
       "4.0     31266\n",
       "1.0      1660\n",
       "2.0      1660\n",
       "Name: evolution_label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "test_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=train_X, columns=df.columns[:-1])"
   ]
  },
  {
   "source": [
    "## Two-stage approach\n",
    "### 1. Stage: Change Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_stage1_data(X, y: pd.Series) -> ('X', 'y'):\n",
    "    '''Simplify dataset classes to 0 -> 0, other -> 1.'''\n",
    "    y_stg1 = y.apply(lambda elem: 0 if elem == 0 else 1)\n",
    "    return X, y_stg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_stg1, train_Y_stg1 = prepare_stage1_data(train_X, train_Y)\n",
    "train_Y_stg1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_stg1, test_Y_stg1 = prepare_stage1_data(test_X, test_Y)\n",
    "test_Y_stg1.value_counts()"
   ]
  },
  {
   "source": [
    "### 2. Stage: Change Type Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def prepare_stage2_data(X, y, columns) -> ('X', 'y'):\n",
    "    '''Remove class 0 from dataset.'''\n",
    "    xy = pd.DataFrame(data=X, columns=columns)\n",
    "    xy['evolution_label'] = y\n",
    "\n",
    "    # remove class 0\n",
    "    tmp = xy.loc[xy['evolution_label'] != 0.0].reset_index(drop=True)\n",
    "    X_stg2 = tmp[tmp.columns[:-1]]\n",
    "    Y_stg2 = tmp[tmp.columns[-1]]\n",
    "    \n",
    "    return X_stg2, Y_stg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_stg2, train_Y_stg2 = prepare_stage2_data(train_X, train_Y, columns=training.columns[:-1])\n",
    "train_Y_stg2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_stg2, test_Y_stg2 = prepare_stage2_data(test_X, test_Y, columns=testing.columns[:-1])\n",
    "test_Y_stg2.value_counts()"
   ]
  },
  {
   "source": [
    "## Balancing of Training Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_stg1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y_stg2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import DataSampler\n",
    "sampler = DataSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing by downsampling\n",
    "\n",
    "train_X_stg1, train_Y_stg1 = sampler.sample_fixed_size(train_X_stg1, train_Y_stg1, size=20000)\n",
    "train_Y_stg1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balancing by downsampling \n",
    "\n",
    "train_X_stg2, train_Y_stg2 = sampler.sample_fixed_size(train_X_stg2, train_Y_stg2, size=10000)\n",
    "train_Y_stg2.value_counts()"
   ]
  },
  {
   "source": [
    "## Principal Components"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "train_Xp_stg1 = pca.fit_transform(train_X_stg1)\n",
    "test_Xp_stg1 = pca.transform(test_X_stg1)\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "train_Xp_stg2 = pca.fit_transform(train_X_stg2)\n",
    "test_Xp_stg2 = pca.transform(test_X_stg2)"
   ]
  },
  {
   "source": [
    "## Evaluation Reports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def print_report(clfs: list, test_Xs: list, test_Y: 'y', titles: list):\n",
    "    \"\"\"\n",
    "    Prints all reports.\n",
    "    :param clfs: list of classifiers to evaluate\n",
    "    :param test_Xs: list of test_X for the corresponding classifier at idx\n",
    "    :param test_Y: true classes\n",
    "    :param titles: list of titles for the classifiers at idx\n",
    "    \"\"\"\n",
    "    for clf, test_X, title in zip(clfs, test_Xs, titles):\n",
    "        pred_Y = clf.predict(test_X)        \n",
    "        print(f\"### {title} ###\\n\", sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "def export_model(model, model_name):\n",
    "    return\n",
    "    \n",
    "    with open(f'data/{use_case}/ml_output/{approach}/{layer_name}_{model_name}.model', 'wb') as f:\n",
    "        pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(clf1, clf2, test_X) -> 'pred_y':\n",
    "    '''Runs the two-stage approach by predicting first with clf1 then clf2.'''\n",
    "    # STG 1\n",
    "    pred_Y_stg1 = clf1.predict(test_X)   \n",
    "\n",
    "    # merge original X with predicted change Y1\n",
    "    test_xy = pd.DataFrame(data=test_X, columns=testing.columns[:-1])\n",
    "    test_xy['evolution_label'] = pred_Y_stg1\n",
    "    \n",
    "    # create new test set with from all predicted change=1\n",
    "    test_xy_stg2 = test_xy.loc[test_xy['evolution_label'] == 1.0]\n",
    "    test_X_stg2 = test_xy_stg2[test_xy_stg2.columns[:-1]]\n",
    "\n",
    "    # STG 2\n",
    "    pred_Y_stg2 = clf2.predict(test_X_stg2)\n",
    "\n",
    "    # merge stg2 X with predicted change type Y2\n",
    "    test_xy_stg2 = test_X_stg2\n",
    "    test_xy_stg2['evolution_label'] = pred_Y_stg2\n",
    "\n",
    "    # merge results based on original index (pred class 0 stays 0)\n",
    "    test_xy['evolution_label'].update(test_xy_stg2['evolution_label'])\n",
    "    pred_Y = test_xy['evolution_label']\n",
    "\n",
    "    return pred_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Xp, train_Y = train_X_stg1, train_Xp_stg1, train_Y_stg1\n",
    "test_X, test_Xp, test_Y = test_X_stg1, test_Xp_stg1, test_Y_stg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Xp, train_Y = train_X_stg2, train_Xp_stg2, train_Y_stg2\n",
    "test_X, test_Xp, test_Y = test_X_stg2, test_Xp_stg2, test_Y_stg2"
   ]
  },
  {
   "source": [
    "# Naive Bayes\n",
    "Working best with _Xp_\n",
    "\n",
    "Stage 1: 68% accuracy/f1 score (Xp) \n",
    "Parameters: \n",
    "- priors: prior probabilities of classes, _None_\n",
    "- var\\_smoothing: \\[0, 1\\] _1E-9_\n",
    "\n",
    "Stage 2: 40% accuracy, 38% f1 with Xp\n",
    "Parameters: \n",
    "- None\n",
    "- 1E-9"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "priors = None # np.array([2,2,1,1]) / (2+2+1+1)\n",
    "smoothing = 1E-9\n",
    "\n",
    "clf = GaussianNB(priors=priors, var_smoothing=smoothing)\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "clf_p = GaussianNB(priors=priors, var_smoothing=smoothing)\n",
    "clf_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([clf, clf_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(clf, 'nb_x')\n",
    "export_model(clf_p, 'nb_xp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report([clf, clf_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Support Vector Machine\n",
    "Stage 1: 69% accuracy/f1\n",
    "Parameters:\n",
    "- C (regularization): <1, _1_, >1, def=1\n",
    "- kernel: _linear_, rbf, poly, sigmoid, def=rbf\n",
    "- gamma (for rbf, poly, sigmoid): scale, auto, float, def=scale\n",
    "- class\\_weight: _None_, balanced, dict, def=None\n",
    "\n",
    "Stage 2: 44% accuracy/f1\n",
    "Parameters:\n",
    "- 10\n",
    "- rbf\n",
    "- scale\n",
    "- None\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "c = 10\n",
    "kernel = 'rbf'\n",
    "gamma = 'scale'\n",
    "weights = None\n",
    "\n",
    "print('x.')\n",
    "svc = SVC(C=c, kernel=kernel, gamma=gamma, class_weight=weights)\n",
    "svc.fit(train_X, train_Y)\n",
    "\n",
    "print('xp.')\n",
    "svc_p = SVC(C=c, kernel=kernel, gamma=gamma, class_weight=weights)\n",
    "svc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print('report.')\n",
    "print_report([svc, svc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(svc, 'svc_x')\n",
    "export_model(svc_p, 'svc_xp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report([svc, svc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# K-nearest Neighbors\n",
    "\n",
    "Stage 1: 70% accuracy, 70% f1 score\n",
    "Parameters:\n",
    "- n\\_neighbors: _30_\n",
    "- weights: _uniform_, distance\n",
    "- algorithm: _auto_, ball_tree, kd_tree, brute\n",
    "- leaf\\_size: _50_ (no difference)\n",
    "\n",
    "Stage 2: 46% accuracy/f1 \n",
    "Parameters:\n",
    "- _20_\n",
    "- uniform\n",
    "- auto\n",
    "- _30_\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 20\n",
    "weights = 'uniform'\n",
    "algo = 'auto'\n",
    "leaf_size = 30\n",
    "\n",
    "knnc1 = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "knnc1.fit(train_X, train_Y)\n",
    "\n",
    "knnc1_p = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "knnc1_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([knnc1, knnc1_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Decision Tree\n",
    "Working well with _Xp_\n",
    "\n",
    "Stage 1: 69% accuracy/f1 with Xp\n",
    "Parameters:\n",
    "- criterion: _gini_, entropy\n",
    "- splitter: best, _random_\n",
    "- max\\_depth: _None_ default=None\n",
    "- min\\_samples\\_leaf (to construct leaf): _2_ default=1\n",
    "- min\\_impurity\\_decrease (split if the impurity is then decreased by): _0_ default=0\n",
    "- ccp\\_alpha (max allowed cost after pruning): _1E-2_ default=0/nopruning\n",
    "\n",
    "Stage 2: 43% accuracy/f1 with X\n",
    "Parameters:\n",
    "- gini\n",
    "- random\n",
    "- None\n",
    "- 2\n",
    "- 0\n",
    "- _0_\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "criterion = 'gini'\n",
    "splitter = 'random'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease = 0 # impurity improvement needed to split\n",
    "ccp_alpha = 0\n",
    "\n",
    "seed=42\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\n",
    "dtc.fit(train_X, train_Y)\n",
    "\n",
    "dtc_p = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha, random_state=seed)\n",
    "dtc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([dtc, dtc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(dtc, 'dt_x')\n",
    "export_model(dtc_p, 'dt_xp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report([dtc, dtc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Random Forest\n",
    "Stage 1: 69% accuracy/f1\n",
    "Parameters:\n",
    "- n\\_estimators: _100_ def=100\n",
    "- criterion: _gini_, entropy\n",
    "- max\\_depth: _None_ def=None\n",
    "- min\\_samples\\_leaf (to construct leaf): _2_ def=1\n",
    "- min\\_impurity\\_decrease (split if the impurity is then decreased by): _1E-2_ default=0\n",
    "- bootstrap (if bootstraped sample is used): _True_ def=True\n",
    "\n",
    "Stage 2: 44% accuracy/f1\n",
    "Parameters:\n",
    "- 100\n",
    "- _entropy_\n",
    "- None\n",
    "- 2\n",
    "- _0_\n",
    "- True\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators = 100\n",
    "criterion = 'entropy'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease = 0\n",
    "bootstrap=True\n",
    "\n",
    "seed=42\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, random_state=seed)\n",
    "rfc.fit(train_X, train_Y)\n",
    "\n",
    "rfc_p = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap, random_state=seed)\n",
    "rfc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([rfc, rfc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(rfc, 'rf_x')\n",
    "export_model(rfc_p, 'rf_xp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report([rfc, rfc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Boosting\n",
    "Stage 1: 71% accuracy/f1\n",
    "Parameters:\n",
    "- base\\_estimator: object, _None(DT)_\n",
    "- n\\_estimators: _50_ def=50\n",
    "- learning\\_rate: _1_ def=1.0\n",
    "- algorithm: SAMME, _SAMME.R_\n",
    "\n",
    "Stage 2: 46% accuracy, 45% f1\n",
    "Parameters:\n",
    "- None\n",
    "- 50\n",
    "- 1\n",
    "- SAMME.R\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_estimator = None\n",
    "n_estimators= 50\n",
    "learning_rate = 1\n",
    "algo = 'SAMME.R'\n",
    "\n",
    "seed=42\n",
    "\n",
    "bc = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "bc.fit(train_X, train_Y)\n",
    "\n",
    "bc_p = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "bc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([bc, bc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])\n",
    "\n",
    "export_model(bc, 'boost_x')\n",
    "export_model(bc_p, 'boost_xp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_report([bc, bc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Pipeline Approach\n",
    "Pipeline from best classifier for each stage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pipeline with KNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 30\n",
    "weights = 'uniform'\n",
    "algo = 'auto'\n",
    "leaf_size = 50\n",
    "\n",
    "knnc1 = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "knnc1.fit(train_X_stg1, train_Y_stg1)\n",
    "\n",
    "print_report([knnc1], [test_X_stg1], test_Y_stg1, [\"stg1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors = 20\n",
    "weights = 'uniform'\n",
    "algo = 'auto'\n",
    "leaf_size = 30\n",
    "\n",
    "knnc2 = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights,  algorithm=algo, leaf_size=leaf_size)\n",
    "knnc2.fit(train_X_stg2, train_Y_stg2)\n",
    "\n",
    "print_report([knnc2], [test_X_stg2], test_Y_stg2, [\"stg2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = predict_all(knnc1, knnc2, test_X)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "## Pipeline with Boosting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_estimator = None\n",
    "n_estimators= 50\n",
    "learning_rate = 1\n",
    "algo = 'SAMME.R'\n",
    "\n",
    "seed=42\n",
    "\n",
    "bc1 = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "bc1.fit(train_X_stg1, train_Y_stg1)\n",
    "\n",
    "bc2 = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, learning_rate=learning_rate, algorithm=algo, random_state=seed)\n",
    "bc2.fit(train_X_stg2, train_Y_stg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Y = predict_all(bc1, bc2, test_X)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "## Final Decision: KNN then Boosting(DT)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n         0.0       0.68      0.61      0.64    133643\n         1.0       0.01      0.05      0.01      1660\n         2.0       0.01      0.15      0.02      1660\n         3.0       0.18      0.21      0.19     32255\n         4.0       0.15      0.04      0.06     31266\n\n    accuracy                           0.45    200484\n   macro avg       0.21      0.21      0.19    200484\nweighted avg       0.51      0.45      0.47    200484\n\n"
     ]
    }
   ],
   "source": [
    "pred_Y = predict_all(knnc1, bc2, test_X)\n",
    "\n",
    "print(sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  }
 ]
}