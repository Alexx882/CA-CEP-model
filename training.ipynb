{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0ac79ad19892b6e891e8d97ca5fdbb2e2457e6e4ba8b10fb20aa9e37280e031f3",
   "display_name": "Python 3.7.8  ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac79ad19892b6e891e8d97ca5fdbb2e2457e6e4ba8b10fb20aa9e37280e031f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Single-Context Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'CallTypeLayer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "df: DataFrame = pd.read_csv(f'output/cluster_metrics/data/{layer_name}.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "def split_data(dataframe, test_dataset_frac=.2, shuffle=False) -> '(training_data, test_data)':\n",
    "    if shuffle:\n",
    "        dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    training_size = int(len(dataframe) * (1-test_dataset_frac))\n",
    "\n",
    "    train = dataframe[:training_size]\n",
    "    test = dataframe[training_size:]\n",
    "\n",
    "    y_train = train[train.columns[-1]]\n",
    "    y_test = test[test.columns[-1]]\n",
    "  \n",
    "    print(f\"\\nWorking with: {len(train)} training points + {len(test)} test points ({len(test)/(len(test)+len(train))} test ratio).\")\n",
    "    print(f\"Label Occurrences: Total = {collections.Counter(y_train.tolist() + y_test.tolist())}, \"\\\n",
    "          f\"Training = {collections.Counter(y_train)}, Test = {collections.Counter(y_test)}\")\n",
    "    # try:\n",
    "    #     print(f\"Label Majority Class: Training = {stat.mode(Y_train)}, Test = {stat.mode(Y_test)}\\n\")\n",
    "    # except stat.StatisticsError:\n",
    "    #     print(f\"Label Majority Class: no unique mode; found 2 equally common values\")\n",
    "\n",
    "    return train, test\n",
    "\n",
    "training, testing = split_data(df, shuffle=False)"
   ]
  },
  {
   "source": [
    "## Standardization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "train_X = scaler.fit_transform(training)[:,:-1] # all except y\n",
    "train_Y = training.iloc[:,-1].to_numpy()\n",
    "\n",
    "test_X = scaler.transform(testing)[:,:-1] # all except y\n",
    "test_Y = testing.iloc[:,-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=test_X, columns=df.columns[:-1])"
   ]
  },
  {
   "source": [
    "## Principal Components"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "train_Xp = pca.fit_transform(train_X)\n",
    "test_Xp = pca.transform(test_X)"
   ]
  },
  {
   "source": [
    "## Evaluation Reports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def print_report(clfs: list, test_Xs: list, test_Y: 'y', titles: list):\n",
    "    \"\"\"\n",
    "    Prints all reports.\n",
    "    :param clfs: list of classifiers to evaluate\n",
    "    :param test_Xs: list of test_X for the corresponding classifier at idx\n",
    "    :param test_Y: true classes\n",
    "    :param titles: list of titles for the classifiers at idx\n",
    "    \"\"\"\n",
    "    for clf, test_X, title in zip(clfs, test_Xs, titles):\n",
    "        pred_Y = clf.predict(test_X)        \n",
    "        print(f\"### {title} ###\\n\", sklearn.metrics.classification_report(y_true=test_Y, y_pred=pred_Y))"
   ]
  },
  {
   "source": [
    "# Naive Bayes\n",
    "Working best with _Xp_\n",
    "\n",
    "Parameters: \n",
    "- priors: prior probabilities of classes, _none_\n",
    "- var\\_smoothing: \\[_0_ , 1\\]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n               precision    recall  f1-score   support\n\n         1.0       0.55      0.33      0.41        18\n         2.0       0.37      0.58      0.45        12\n\n    accuracy                           0.43        30\n   macro avg       0.46      0.46      0.43        30\nweighted avg       0.47      0.43      0.43        30\n\n### Xp ###\n               precision    recall  f1-score   support\n\n         1.0       0.69      0.50      0.58        18\n         2.0       0.47      0.67      0.55        12\n\n    accuracy                           0.57        30\n   macro avg       0.58      0.58      0.57        30\nweighted avg       0.60      0.57      0.57        30\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(train_X, train_Y)\n",
    "\n",
    "clf_p = GaussianNB()\n",
    "clf_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([clf, clf_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Support Vector Machine\n",
    "Parameters:\n",
    "- kernel: _linear_, rbf, poly, sigmoid\n",
    "- C (regularization): <1, _1_, >1\n",
    "- class\\_weight: _None_, balanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n               precision    recall  f1-score   support\n\n         1.0       0.87      0.72      0.79        18\n         2.0       0.67      0.83      0.74        12\n\n    accuracy                           0.77        30\n   macro avg       0.77      0.78      0.76        30\nweighted avg       0.79      0.77      0.77        30\n\n### Xp ###\n               precision    recall  f1-score   support\n\n         1.0       0.44      0.22      0.30        18\n         2.0       0.33      0.58      0.42        12\n\n    accuracy                           0.37        30\n   macro avg       0.39      0.40      0.36        30\nweighted avg       0.40      0.37      0.35        30\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "c= 1\n",
    "\n",
    "svc = SVC(kernel='linear', C=c)\n",
    "svc.fit(train_X, train_Y)\n",
    "\n",
    "svc_p = SVC(kernel='linear', C=c)\n",
    "svc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([svc, svc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# K-nearest Neighbors\n",
    "Parameters:\n",
    "- n\\_neighbors: 4\n",
    "- weights: _uniform_, distance\n",
    "- algorithm: _auto_, ball_tree, kd_tree, brute\n",
    "- leaf\\_size:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n               precision    recall  f1-score   support\n\n         1.0       0.58      0.83      0.68        18\n         2.0       0.25      0.08      0.12        12\n\n    accuracy                           0.53        30\n   macro avg       0.41      0.46      0.40        30\nweighted avg       0.45      0.53      0.46        30\n\n### Xp ###\n               precision    recall  f1-score   support\n\n         1.0       0.58      0.78      0.67        18\n         2.0       0.33      0.17      0.22        12\n\n    accuracy                           0.53        30\n   macro avg       0.46      0.47      0.44        30\nweighted avg       0.48      0.53      0.49        30\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "n_neighbors=4\n",
    "weights= 'uniform'\n",
    "algo=  'auto'\n",
    "leaf_size = 30\n",
    "\n",
    "knnc = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, algorithm=algo, leaf_size=leaf_size)\n",
    "knnc.fit(train_X, train_Y)\n",
    "\n",
    "knnc_p = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights,  algorithm=algo, leaf_size=leaf_size)\n",
    "knnc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([knnc, knnc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Decision Tree\n",
    "Working well with _Xp_\n",
    "\n",
    "Parameters:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "### X ###\n               precision    recall  f1-score   support\n\n         1.0       0.71      0.67      0.69        18\n         2.0       0.54      0.58      0.56        12\n\n    accuracy                           0.63        30\n   macro avg       0.62      0.62      0.62        30\nweighted avg       0.64      0.63      0.64        30\n\n### Xp ###\n               precision    recall  f1-score   support\n\n         1.0       0.50      0.33      0.40        18\n         2.0       0.33      0.50      0.40        12\n\n    accuracy                           0.40        30\n   macro avg       0.42      0.42      0.40        30\nweighted avg       0.43      0.40      0.40        30\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "criterion = 'gini'\n",
    "splitter = 'random'\n",
    "max_depth = 10\n",
    "min_samples_leaf = 1\n",
    "min_impurity_decrease= 0 # impurity improvement needed to split\n",
    "ccp_alpha = 0.001\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha)\n",
    "dtc.fit(train_X, train_Y)\n",
    "\n",
    "dtc_p = DecisionTreeClassifier(criterion=criterion, splitter=splitter, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, ccp_alpha=ccp_alpha)\n",
    "dtc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([dtc, dtc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Random Forest\n",
    "Parameters:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_estimators = 100\n",
    "criterion = 'entropy'\n",
    "max_depth = None\n",
    "min_samples_leaf = 2\n",
    "min_impurity_decrease= 0\n",
    "bootstrap=True\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap)\n",
    "rfc.fit(train_X, train_Y)\n",
    "\n",
    "rfc_p = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_impurity_decrease=min_impurity_decrease, bootstrap=bootstrap)\n",
    "rfc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([rfc, rfc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  },
  {
   "source": [
    "# Boosting\n",
    "Parameters:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "base_estimator= GaussianNB()#SVC(kernel='linear')\n",
    "n_estimators= 100\n",
    "algo = 'SAMME.R'\n",
    "learning_rate = .3\n",
    "\n",
    "bc = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, algorithm=algo, learning_rate=learning_rate)\n",
    "bc.fit(train_X, train_Y)\n",
    "\n",
    "bc_p = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n_estimators, algorithm=algo, learning_rate=learning_rate)\n",
    "bc_p.fit(train_Xp, train_Y)\n",
    "\n",
    "print_report([bc, bc_p], [test_X, test_Xp], test_Y, [\"X\", \"Xp\"])"
   ]
  }
 ]
}