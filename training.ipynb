{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0ac79ad19892b6e891e8d97ca5fdbb2e2457e6e4ba8b10fb20aa9e37280e031f3",
   "display_name": "Python 3.7.8  ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac79ad19892b6e891e8d97ca5fdbb2e2457e6e4ba8b10fb20aa9e37280e031f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Contextualization\n",
    "Raw transactional data is loaded and columns of interest are identified for contextualization (layering)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Clustering\n",
    "Each layer is clustered independently over all time windows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Temporal Community Segmentation\n",
    "Clusters are split up based on their timestamp into multiple time windows\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Feature Engineering\n",
    "_Features are extracted for each cluster:_\n",
    "- cluster size\n",
    "- cluster standard deviation\n",
    "- cluster scarcity\n",
    "- cluster popularity (importance I)\n",
    "- cluster diversity (importance II)\n",
    "\n",
    "new:\n",
    "- ??? (range/needed space)\n",
    "- center\n",
    "\n",
    "\n",
    "_Features are extracted for each layer:_\n",
    "- relative cluster sizes\n",
    "- layer entropy\n",
    "- distance from global centers\n",
    "\n",
    "new:\n",
    "- number of nodes\n",
    "- number of clusters\n",
    "- center of clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Cluster Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import json\n",
    "import os\n",
    "from entities import TimeWindow, Cluster\n",
    "\n",
    "def calculate_metrics_for_clusters(layer_name: str, feature_names: List[str]):\n",
    "    '''\n",
    "    :param layer_name: Name of the layer for which multiple time windows exist\n",
    "    :param feature_names: Features of the layer\n",
    "    '''\n",
    "    print(f\"Working on {layer_name}\")\n",
    "\n",
    "    path_in = f'input/timeslices/{layer_name}'\n",
    "    path_out = f'input/metrics/{layer_name}.json'\n",
    "\n",
    "    complete_clusters: List[Cluster] = []\n",
    "\n",
    "    for root, _, files in os.walk(path_in):\n",
    "        for f in files:\n",
    "            with open(os.path.join(root, f), 'r') as file:\n",
    "                # for each time window json\n",
    "                json_slice = json.loads(file.read())\n",
    "                time_window = TimeWindow.create_from_serializable_dict(json_slice)\n",
    "\n",
    "                # create all clusters + metrics for one time window\n",
    "                clusters = Cluster.create_multiple_from_time_window(time_window, feature_names)\n",
    "                complete_clusters.extend(clusters)\n",
    "        \n",
    "    # store the cluster metrics\n",
    "    with open(path_out, 'w') as file:\n",
    "        file.write(json.dumps([cl.__dict__ for cl in complete_clusters]))"
   ]
  }
 ]
}